{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try estimating sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = np.linspace(0,1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = np.sin(x_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        #make a 2 HL 64 neuron network, fully connected, and test its power\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.pi = nn.Sequential(nn.Linear(input_size, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(64, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(64, output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.pi(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnet = Network(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 7.4210e-01],\n",
       "         [-6.2422e-01],\n",
       "         [ 7.0136e-02],\n",
       "         [ 6.9494e-01],\n",
       "         [-1.3752e-01],\n",
       "         [-7.6551e-01],\n",
       "         [ 3.0112e-01],\n",
       "         [ 4.3266e-02],\n",
       "         [ 7.8482e-01],\n",
       "         [-7.1765e-01],\n",
       "         [-3.2632e-01],\n",
       "         [-1.1904e-01],\n",
       "         [-2.9981e-01],\n",
       "         [-7.8621e-01],\n",
       "         [-9.1743e-04],\n",
       "         [-8.1548e-01],\n",
       "         [ 3.4327e-01],\n",
       "         [ 7.8124e-01],\n",
       "         [-7.9956e-01],\n",
       "         [ 5.8061e-01],\n",
       "         [ 8.3889e-03],\n",
       "         [ 2.4761e-02],\n",
       "         [ 2.6582e-01],\n",
       "         [ 4.6382e-01],\n",
       "         [ 8.5130e-01],\n",
       "         [ 7.2295e-01],\n",
       "         [ 5.5010e-01],\n",
       "         [-3.8199e-01],\n",
       "         [-3.0772e-01],\n",
       "         [ 1.2265e-01],\n",
       "         [ 5.2200e-01],\n",
       "         [ 5.2562e-01],\n",
       "         [ 7.2379e-01],\n",
       "         [ 9.0143e-01],\n",
       "         [ 5.6913e-01],\n",
       "         [ 4.6732e-01],\n",
       "         [-7.7757e-01],\n",
       "         [-3.2066e-01],\n",
       "         [-7.5434e-01],\n",
       "         [-9.6266e-01],\n",
       "         [ 4.8659e-01],\n",
       "         [ 1.9320e-01],\n",
       "         [ 4.4647e-01],\n",
       "         [-8.0976e-01],\n",
       "         [-4.5532e-01],\n",
       "         [-8.4473e-01],\n",
       "         [ 2.2846e-01],\n",
       "         [-3.2266e-01],\n",
       "         [ 2.4671e-01],\n",
       "         [ 1.0395e-01],\n",
       "         [-5.9268e-01],\n",
       "         [-5.2343e-01],\n",
       "         [ 4.5550e-01],\n",
       "         [ 4.8299e-01],\n",
       "         [-5.8275e-01],\n",
       "         [-8.7347e-01],\n",
       "         [-7.3738e-01],\n",
       "         [-1.5505e-01],\n",
       "         [-6.8260e-01],\n",
       "         [ 9.3430e-01],\n",
       "         [ 1.0197e-03],\n",
       "         [-1.6082e-01],\n",
       "         [ 3.2544e-01],\n",
       "         [ 8.9288e-01]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.0840,  0.6905, -0.1890,  0.1568, -0.4945, -0.5531, -0.3028,  0.3342,\n",
       "          0.5794,  0.0169, -0.8359,  0.3846,  0.2323,  0.5918, -0.9207,  0.2717,\n",
       "         -0.4692, -0.1173, -0.2291,  0.0560,  0.7398, -0.5039,  0.7710, -0.4311,\n",
       "          0.6332, -0.2650, -0.6536,  0.0588,  0.2833,  0.3888, -0.6439,  0.9630,\n",
       "         -0.9801,  0.3601, -0.2833,  0.2959, -0.8412,  0.2857,  0.2940,  0.9770,\n",
       "         -0.9391,  0.8277,  0.2596, -0.8732, -0.1003,  0.2981,  0.4013, -0.8107,\n",
       "          0.4554,  0.5267, -0.3842,  0.1552,  0.2680,  0.0094, -0.4834,  0.2393,\n",
       "          0.2542,  0.4853,  0.0504, -0.6253, -0.6352, -0.0950, -0.0041,  0.9876],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0021,  0.0596, -0.0498,  ...,  0.0950, -0.0707,  0.0297],\n",
       "         [ 0.0099,  0.0624,  0.0447,  ..., -0.0254, -0.1107, -0.0326],\n",
       "         [ 0.1039,  0.0662, -0.0383,  ..., -0.0658, -0.0144,  0.0227],\n",
       "         ...,\n",
       "         [-0.0169,  0.0164,  0.0972,  ..., -0.0169,  0.0269, -0.1214],\n",
       "         [ 0.0053, -0.0495,  0.0379,  ...,  0.0415,  0.0959,  0.0673],\n",
       "         [-0.1065, -0.0667, -0.1003,  ...,  0.0887, -0.0722,  0.0117]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0717,  0.1095, -0.1087, -0.0525, -0.0868, -0.0951,  0.1032, -0.0581,\n",
       "         -0.0485,  0.0852, -0.1147, -0.0982,  0.0385, -0.0300,  0.0383, -0.0294,\n",
       "          0.0934,  0.0308, -0.0453,  0.0452,  0.0854, -0.0003,  0.0198, -0.0327,\n",
       "          0.0033,  0.0887,  0.0847,  0.1158, -0.0324,  0.0455, -0.0398, -0.0435,\n",
       "          0.1246, -0.0068, -0.0438, -0.0568,  0.0254,  0.0817, -0.0103, -0.0015,\n",
       "         -0.0940, -0.1227,  0.0360, -0.1145, -0.0192,  0.0499, -0.0647, -0.0026,\n",
       "          0.0050,  0.0098,  0.0304, -0.0555,  0.1166, -0.0637,  0.0999,  0.1018,\n",
       "         -0.0540,  0.0637,  0.0327, -0.0972, -0.0142, -0.0570,  0.0441, -0.0517],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0378, -0.0096,  0.0855,  0.0344, -0.0719, -0.0646, -0.1065, -0.0170,\n",
       "          -0.0850, -0.0702, -0.0206, -0.0928, -0.0500, -0.0510,  0.0818,  0.1190,\n",
       "           0.0421, -0.0200, -0.0838, -0.0555, -0.1004,  0.0068,  0.0611, -0.0201,\n",
       "          -0.0990, -0.1107, -0.1072,  0.0644, -0.0225,  0.0585,  0.0569, -0.0553,\n",
       "          -0.1061,  0.0286,  0.1037, -0.0558, -0.0892,  0.0224, -0.0155,  0.1214,\n",
       "          -0.0483,  0.1169, -0.1089,  0.0280, -0.1043,  0.1238,  0.1211,  0.0854,\n",
       "           0.0749, -0.0024, -0.0593,  0.0699,  0.0184,  0.0167,  0.0301, -0.0325,\n",
       "           0.0985, -0.1119,  0.0252, -0.0537,  0.0946,  0.0008, -0.1218, -0.1086]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.0644], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learnable parameters\n",
    "list(testnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yin = np.array([y_set[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = np.array([x_set[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputx = torch.from_numpy(xin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputy = torch.from_numpy(yin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnet = testnet.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = testnet(inputx.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero the grad so we start over, or else grad will compound\n",
    "testnet.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(out.double(), inputy.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0020, dtype=torch.float64, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backprop\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#easy SGD\n",
    "#new_param = old_param + (grad*lr)\n",
    "lr = 1e-3\n",
    "\n",
    "for param in testnet.parameters():\n",
    "    #f.data.sub_(f.grad.data * learning_rate)\n",
    "    param.data.sub_(param.grad.data*lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead, use optimizers form torch.optim\n",
    "optimizer = optim.SGD(testnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in training:\n",
    "optimizer.zero_grad()\n",
    "out = testnet(inputx.double())\n",
    "loss = criterion(out.double(), inputy.double())\n",
    "loss.backward() #calc backwards\n",
    "optimizer.step() #do the actual update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset\n",
    "x = np.linspace(0,6,10000)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "optimizer = optim.SGD(testnet.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr MSE loss on test: 0.0001\n",
      "curr MSE loss on test: 0.0001\n",
      "curr MSE loss on test: 0.0\n",
      "curr MSE loss on test: 0.0004\n",
      "curr MSE loss on test: 0.0\n",
      "curr MSE loss on test: 0.0001\n",
      "curr MSE loss on test: 0.0\n",
      "curr MSE loss on test: 0.003\n",
      "curr MSE loss on test: 0.0\n",
      "curr MSE loss on test: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    testnet.train()\n",
    "    \n",
    "    for xval, yval in dataloader:\n",
    "        #unsqueeze just puts in in row form\n",
    "        yval = yval.double()\n",
    "        xval = xval.double()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = testnet(xval.unsqueeze(1))\n",
    "        loss = criterion(out, yval.unsqueeze(1))\n",
    "        loss.backward() #calc backwards\n",
    "        optimizer.step() #do update\n",
    "        \n",
    "    #print some stats\n",
    "    if epoch%10 ==0:\n",
    "        with torch.no_grad():\n",
    "            testxval = torch.from_numpy(np.random.rand(1)*6)\n",
    "            testyval = torch.from_numpy(np.array([np.sin(testxval.item())]))\n",
    "\n",
    "            pred = testnet(testxval.double())\n",
    "            testloss = criterion(pred.double(), testyval.double())\n",
    "\n",
    "            print(f'curr MSE loss on test: {round(testloss.item(),4)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1)*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98194848])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (pi): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9796]], dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnet(torch.tensor([x]).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
